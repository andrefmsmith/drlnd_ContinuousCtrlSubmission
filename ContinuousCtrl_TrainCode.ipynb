{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control with DDPG and Reacher - Training Code\n",
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from unityagents import UnityEnvironment\n",
    "from collections import namedtuple, deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Environment and Key Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "### Set the path to Unity Reacher Environment Executable\n",
    "env = UnityEnvironment(file_name='Reacher_Windows_x86_64/Reacher.exe')\n",
    "\n",
    "### Extract brain_name, action size and state size\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "action_size = brain.vector_action_space_size\n",
    "state_size = env_info.vector_observations.shape[1]\n",
    "\n",
    "### Pick which device for training\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(3e6)     # replay buffer size\n",
    "BATCH_SIZE = 1024          # minibatch size\n",
    "GAMMA = 0.99               # discount factor\n",
    "TAU = 1e-3                 # for soft update of target parameters\n",
    "LR_ACTOR = 1e-4            # learning rate of the actor \n",
    "LR_CRITIC = 2e-4           # learning rate of the critic\n",
    "update_every = 20          # number of timesteps after which to run an update\n",
    "SN = 0.25                  # starting value for additive noise scale (exploratory actions)\n",
    "ND = 0.99999               # noise decay rate (exploratory actions)\n",
    "NM = 0.01                  # noise minimum to be maintained (exploratory actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDPG Agent & Methods\n",
    "______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Actor and Critic network architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hu=(400, 300), activ_in = F.relu, activ_out = torch.tanh):\n",
    "        super(Actor, self).__init__()\n",
    "        \n",
    "        self.activ_in = activ_in\n",
    "        self.activ_out = activ_out\n",
    "        \n",
    "        self.input_layer = nn.Linear(state_size, hu[0])\n",
    "        self.hl1 = nn.Linear(hu[0], hu[1])\n",
    "        self.output_layer = nn.Linear(hu[-1], action_size)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = state\n",
    "        x = self.activ_in(self.input_layer(x))\n",
    "        x = self.activ_in(self.hl1(x))\n",
    "        return self.activ_out(self.output_layer(x))  \n",
    "    \n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hu=(400, 300), activ_in = F.relu):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.activ_in = activ_in\n",
    "        \n",
    "        self.input_layer = nn.Linear(state_size, hu[0])\n",
    "        self.hl1 = nn.Linear(hu[0]+action_size, hu[1])        \n",
    "        self.output_layer = nn.Linear(hu[-1], 1)\n",
    "        \n",
    "    def forward(self, state, action):\n",
    "        x = state\n",
    "        u = action\n",
    "        \n",
    "        x = self.activ_in(self.input_layer(x))\n",
    "        x = torch.cat((x, u), dim=1)\n",
    "        x = self.activ_in(self.hl1(x))\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Agent class and its methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, state_size, action_size, start_noise=SN, noise_decay=ND, noise_min=NM, add_noise=True):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        ### Initialise actor online and target networks\n",
    "        self.actor_online = Actor(state_size, action_size).to(device)\n",
    "        self.actor_target = Actor(state_size, action_size).to(device)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_online.parameters(), lr=LR_ACTOR)\n",
    "        \n",
    "        ### Initialise critic online and target networks\n",
    "        self.critic_online = Critic(state_size, action_size).to(device)\n",
    "        self.critic_target = Critic(state_size, action_size).to(device)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_online.parameters(), lr=LR_CRITIC)\n",
    "        \n",
    "        \n",
    "        ### Noise parameters for exploration\n",
    "        self.noise_scale = start_noise\n",
    "        self.noise_decay = noise_decay\n",
    "        self.noise_min = noise_min\n",
    "        \n",
    "        self.add_noise = add_noise\n",
    "        \n",
    "        ### Replay buffer\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE)\n",
    "        \n",
    "        ### Keep track of timesteps since last training update\n",
    "        self.update = 0\n",
    "    \n",
    "    ### Generate random normal noise to add to the action output and enable exploration\n",
    "    def generate_noise(self):\n",
    "        noise = np.random.normal(loc=0, scale=self.noise_scale, size=self.action_size)\n",
    "        self.noise_scale = max(self.noise_decay*self.noise_scale, self.noise_min)\n",
    "        return noise\n",
    "    \n",
    "    ### Store experiences in the replay buffer and control training updates\n",
    "    def step(self, state, action, reward, next_state, done, update_cycles=3):\n",
    "        # Commit experience to memory\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        self.update = (self.update +1)%update_every\n",
    "        \n",
    "        # Run optimisation 'update_cycles' times\n",
    "        c=0\n",
    "        if (self.update==0):\n",
    "            if len(self.memory) > BATCH_SIZE:\n",
    "                while c < update_cycles:\n",
    "                    experiences = self.memory.sample()\n",
    "                    self.learn(experiences, GAMMA)\n",
    "                    c+=1\n",
    "    \n",
    "    ### Use the actor network to select an action. OPTIONAL: add noise to the action (add_noise=True)\n",
    "    def act(self, state):\n",
    "        state = torch.from_numpy(state).float().to(device)\n",
    "        self.actor_online.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.actor_online(state).cpu().data.numpy()\n",
    "        self.actor_online.train()\n",
    "        if self.add_noise:\n",
    "            action += self.generate_noise()\n",
    "        return np.clip(action, -1, 1)\n",
    "    \n",
    "    ### Run a training update from a batch of experiences on the critic and actor online networks and a \n",
    "    ## soft update on the respective target networks\n",
    "    def learn(self, experiences, gamma):\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "        \n",
    "        ### Update critic\n",
    "        actions_next = self.actor_target(next_states)\n",
    "        Q_targets_next = self.critic_target(next_states, actions_next)\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1-dones))\n",
    "        Q_expected = self.critic_online(states, actions)\n",
    "        critic_loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        \n",
    "        # Backprop\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.critic_online.parameters(), 1)\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        \n",
    "        ### Update actor\n",
    "        actions_pred = self.actor_online(states)\n",
    "        actor_loss = -self.critic_online(states, actions_pred).mean()\n",
    "        \n",
    "        # Backprop\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.actor_online.parameters(), 1)\n",
    "        self.actor_optimizer.step()\n",
    "        \n",
    "        \n",
    "        ### Update targets\n",
    "        self.soft_update(self.critic_online, self.critic_target, TAU)\n",
    "        self.soft_update(self.actor_online, self.actor_target, TAU)\n",
    "    \n",
    "    ### Blend together online and target network parameters\n",
    "    def soft_update(self, online_model, target_model, tau):\n",
    "        for target_param, online_param in zip(target_model.parameters(), online_model.parameters()):\n",
    "            target_param.data.copy_(tau*online_param.data + (1.0-tau)*target_param.data)\n",
    "            \n",
    "### Define a Replaybuffer class to store experiences, organise and sample from them\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, action_size, buffer_size, batch_size):\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "    \n",
    "    ### Adds an experience tuple to memory\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "\n",
    "    ### Samples k (batch size) experience tuples randomly from memory\n",
    "    def sample(self):\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "        \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train a DDPG agent, monitor score and save Actor/Critic checkpoints if task solved.\n",
    "def ddpg(output, n_episodes=1000, max_t=1000):\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]           # reset the environment \n",
    "        state = env_info.vector_observations[0]                     # get the current state\n",
    "        score = 0                                                   # initialize the score\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state)                               # select an action\n",
    "            env_info = env.step(action)[brain_name]                 # send action to tne environment\n",
    "            next_state = env_info.vector_observations[0]            # get next state\n",
    "            reward = env_info.rewards[0]                            # get reward\n",
    "            done = env_info.local_done[0]                           # check if episode finished\n",
    "            agent.step(state, action, reward, next_state, done)     # agent takes one step to train\n",
    "            state = next_state                                      # roll over state to next time step\n",
    "            score += reward                                         # update the score\n",
    "            if done:                                                # exit loop if episode finished\n",
    "                break \n",
    "        scores_deque.append(score)\n",
    "        scores.append(score)\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tScore: {:.2f}'.format(i_episode, np.mean(scores_deque), score), end=\"\")\n",
    "        if np.mean(scores_deque)>=30.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_deque)))\n",
    "            torch.save(agent.actor_online.state_dict(), '{}_checkpoint_actor.pth'.format(output))\n",
    "            torch.save(agent.critic_online.state_dict(), '{}_checkpoint_critic.pth'.format(output))\n",
    "            break\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watch a naive agent perform the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score this episode: 0.00\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(state_size, action_size)\n",
    "env_info = env.reset(train_mode=False)[brain_name]   \n",
    "state = env_info.vector_observations                 \n",
    "score = 0                                            \n",
    "agent.add_noise = False\n",
    "for i in range(150):\n",
    "    action = agent.act(state)                        \n",
    "    env_info = env.step(action)[brain_name]           \n",
    "    next_state = env_info.vector_observations[0]      \n",
    "    reward = env_info.rewards[0]                     \n",
    "    done = env_info.local_done[0]                   \n",
    "    score += env_info.rewards[0]                      \n",
    "    state = next_state                               \n",
    "    if done:                                          \n",
    "        break\n",
    "print('Total score this episode: {:.2f}'.format(score))\n",
    "agent.add_noise = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the cell below to re-initialise and train the agent \n",
    "When calling ```ddpg``` add arguments for ```output``` (file name for checkpoint if solved) and ```n_episodes=1000``` to train for if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 465\tAverage Score: 30.04\tScore: 39.51\n",
      "Environment solved in 365 episodes!\tAverage Score: 30.04\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(state_size, action_size)\n",
    "scores = ddpg(output='01.04.2020_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watch a trained agent perform the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]   \n",
    "state = env_info.vector_observations               \n",
    "score = 0                                           \n",
    "agent.add_noise = False\n",
    "for i in range(1000):\n",
    "    action = agent.act(state)                        \n",
    "    env_info = env.step(action)[brain_name]          \n",
    "    next_state = env_info.vector_observations[0]      \n",
    "    reward = env_info.rewards[0]                     \n",
    "    done = env_info.local_done[0]                     \n",
    "    score += env_info.rewards[0]                      \n",
    "    state = next_state                               \n",
    "    if done:                                         \n",
    "        break\n",
    "print('Total score this episode: {:.2f}'.format(score))\n",
    "agent.add_noise = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
